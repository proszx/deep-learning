{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torchtext.datasets import TranslationDataset,Multi30k\n",
    "from torchtext.data import Field,BucketIterator\n",
    "device=torch.device('cuda:0')\n",
    "import spacy\n",
    "import random\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=1024\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_de=spacy.load('de')\n",
    "spacy_en=spacy.load('en')\n",
    "def token_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)][::-1]\n",
    "def token_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "SRC=Field(tokenize=token_de,init_token='<sos>',eos_token='<eos>',lower=True)\n",
    "TRG=Field(tokenize=token_en,init_token='<sos>',eos_token='<eos>',lower=True)\n",
    "train_data,valid_data,test_data=Multi30k.splits(exts=('.de','.en'),fields=(SRC,TRG))\n",
    "\n",
    "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
    "print(f\"Number of testing examples: {len(test_data.examples)}\")\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data,min_freq=2)\n",
    "TRG.build_vocab(train_data,min_freq=2)\n",
    "print(len(SRC.vocab))\n",
    "print(len(TRG.vocab))\n",
    "BATCH_SIZE=128\n",
    "train_iter,valid_iter,test_iter=BucketIterator.splits((train_data,valid_data,test_data),batch_size=BATCH_SIZE,device=device)\n",
    "print(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,input_dim,emb_dim,hid_dim,n_layers,dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim=input_dim\n",
    "        self.emb_dim=emb_dim\n",
    "        self.hid_dim=hid_dim\n",
    "        self.n_layers=n_layers\n",
    "        self.dropout=dropout\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout = dropout)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self,src):\n",
    "        embedded=self.dropout(self.embedding(src))\n",
    "        \n",
    "        outputs,(hidden,cell)=self.rnn(embedded)\n",
    "        \n",
    "        return hidden,cell\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,output_dim,emb_dim,hid_dim,n_layers,dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.emb_dim=emb_dim\n",
    "        self.hid_dim=hid_dim\n",
    "        self.output_dim=output_dim\n",
    "        self.n_layers=n_layers\n",
    "        self.dropout=dropout\n",
    "        \n",
    "        self.embedding=nn.Embedding(output_dim,emb_dim)\n",
    "        \n",
    "        self.rnn=nn.LSTM(emb_dim,hid_dim,n_layers,dropout=dropout)\n",
    "        \n",
    "        self.out=nn.Linear(hid_dim,output_dim)\n",
    "        \n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "    def forward(self,inputs,hidden,cell):\n",
    "        inputs=inputs.unsqueeze(0)\n",
    "        embedded=self.dropout(self.embedding(inputs))\n",
    "        \n",
    "        output,(hidden,cell)=self.rnn(embedded,(hidden,cell))\n",
    "        \n",
    "        prediction=self.out(output.squeeze(0))\n",
    "        \n",
    "        return prediction,hidden,cell\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self,encoder,decoder,device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder=encoder\n",
    "        self.decoder=decoder\n",
    "        self.device=device\n",
    "        \n",
    "        assert encoder.hid_dim==decoder.hid_dim,\\\n",
    "            \"编码层和解码层隐藏层必须相同\"\n",
    "        assert encoder.n_layers==decoder.n_layers,\\\n",
    "            \"编码器解码器层数必须相同\"\n",
    "    def forward(self,src,trg,teacher_forcing_ratio=0.5):\n",
    "        \n",
    "        batch_size=trg.shape[1]\n",
    "        max_len=trg.shape[0]\n",
    "        \n",
    "        trg_vacab_size=self.decoder.output_dim\n",
    "        \n",
    "        outputs=torch.zeros(max_len,batch_size,trg_vacab_size).to(self.device)\n",
    "        \n",
    "        hidden,cell=self.encoder(src)\n",
    "        \n",
    "        inputs=trg[0,:]\n",
    "        \n",
    "        for t in range(1,max_len):\n",
    "            output,hidden,cell=self.decoder(inputs,hidden,cell)\n",
    "            outputs[t]=output\n",
    "            teacher_forcing=random.random()<teacher_forcing_ratio\n",
    "            top1=output.max(1)[1]\n",
    "            inputs=(trg[t] if teacher_forcing else top1)\n",
    "            \n",
    "        return outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
